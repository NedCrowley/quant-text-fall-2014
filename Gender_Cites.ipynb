{
 "metadata": {
  "name": "",
  "signature": "sha256:1ed41c0233083e7c91f6bbca6021c4b392200d31498beecf15a3c3c2de32282a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Author Gender and Citation Patterns \n",
      "Neal Caren\n",
      "\n",
      "\n",
      "Over the summer, [x] released a study that showed that, controlling for other factors, articles in International Relations journals published by men were cited [x%] more often than articles written by women, controlling for other factors. Prominent political science The Monkey Cage, now hosted by the Washington Post, recently ran a forum on this topic and a number of prominent scholars weighed in.\n",
      "\n",
      "To test whether or not this gendered practice in citing work exists, I examined [n] articles published in [x] Sociology journals in 2009 and 2010. Article information, including citation count information is from Web of Science. For each paper, I estimated the author\u2019s (or first author\u2019s in the case of multi author works) sex based on whether their first name is commonly male or female, based on Social Security birth records. To control for method and subfield, I used a topic (LDA) model to estimate 50 latent topics basic on the abstract words. For each article, I estimated the proportion of the abstract that was related to each topic. \n",
      "\n",
      "## Note:\n",
      "So far, I only have a basic model up an running. I still need to include additional controls variables, including article journal and topic. \n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "from collections import Counter\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import sexmachine.detector as gender_detective"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read in the data and print a sample article\n",
      "\n",
      "articles = list(csv.reader(open('soc_articles_details.tsv','r'), delimiter='\\t'))\n",
      "\n",
      "for item in enumerate(articles[35]):\n",
      "    print item"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0, \"Woolfson, Charles. 2010. '`hard Times' in Lithuania: Crisis and `discourses of Discontent' in Post-communist Society.' Ethnography. 11:4 487-514.\")\n",
        "(1, 'Ethnography')\n",
        "(2, '2010')\n",
        "(3, '6')\n",
        "(4, \"This article analyses the intersection of global recession with the underlying crisis of neo-liberalism in Baltic Lithuania, and the disappointment of expectations regarding the promised benefits of free market capitalism for the citizens of post-communist society. Drawing on an empirical analysis of Lithuania, a new European Union member state and former Soviet republic, the post-communist trajectory of neo-liberal economic and social development is critiqued. Global economic and financial crisis has resulted in a social and economic `shock'. It occurred in an environment already marked by disappointment, alienation and high outward migration. Through an analysis of `voice' expressed in `discourses of discontent', the article attempts to chart the impact of `hard times'. It predicts a new `exit' in the form of a surge of outward migration resulting from the failures of `voice', and the concerning possibility of `internal exit'.\")\n",
        "(5, '1')\n",
        "(6, 'Charles Woolfson')\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# I've built my own tool to estimate author gender from first names based on social security birth records,\n",
      "# but when with `sexmachine` library this time.\n",
      "\n",
      "# This function is written specifically for the abstracts name format.\n",
      "\n",
      "dector = gender_detective.Detector()\n",
      "\n",
      "def get_1st_author_gender(authors): \n",
      "    # Just look at the first author'\n",
      "    for author in authors.split(';')[:1]:\n",
      "        first_name = author.split(' ')[0]\n",
      "        return dector.get_gender(first_name)  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# loop through the dataset and gather some stats\n",
      "\n",
      "cites =   []\n",
      "genders = []\n",
      "female =  []\n",
      "\n",
      "for article in articles[1:]:\n",
      "    cite = int(article[3])\n",
      "    cites.append(cite)\n",
      "    \n",
      "    gender =  get_1st_author_gender(article[6])\n",
      "    genders.append(gender)\n",
      "    \n",
      "    if gender == 'female':\n",
      "        female.append(1)\n",
      "    else:\n",
      "        female.append(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Counter(genders)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "Counter({u'male': 1250, u'female': 946, u'andy': 279, u'mostly_female': 86, u'mostly_male': 46})"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Mean', np.mean(cites)\n",
      "print 'Median', np.median(cites)\n",
      "print 'Female', np.mean(female)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mean 6.22516302263\n",
        "Median 3.0\n",
        "Female 0.362869198312\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import regression models\n",
      "from statsmodels.discrete.discrete_model import NegativeBinomial\n",
      "import statsmodels.api as sm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the data in the correct format. Specifically, we need a constant.\n",
      "\n",
      "constant = [1]*len(female)\n",
      "X = zip(constant,female)\n",
      "print X[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(1, 0), (1, 0), (1, 1), (1, 0), (1, 1)]\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = NegativeBinomial(cites, X)\n",
      "results = model.fit()\n",
      "print(results.summary())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Optimization terminated successfully.\n",
        "         Current function value: 2.896065\n",
        "         Iterations: 4\n",
        "         Function evaluations: 5\n",
        "         Gradient evaluations: 5\n",
        "                     NegativeBinomial Regression Results                      \n",
        "==============================================================================\n",
        "Dep. Variable:                      y   No. Observations:                 2607\n",
        "Model:               NegativeBinomial   Df Residuals:                     2605\n",
        "Method:                           MLE   Df Model:                            1\n",
        "Date:                Wed, 29 Oct 2014   Pseudo R-squ.:               0.0001279\n",
        "Time:                        20:28:38   Log-Likelihood:                -7550.0\n",
        "converged:                       True   LL-Null:                       -7551.0\n",
        "                                        LLR p-value:                    0.1646\n",
        "==============================================================================\n",
        "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "const          1.8039      0.029     62.227      0.000         1.747     1.861\n",
        "x1             0.0666      0.048      1.387      0.166        -0.028     0.161\n",
        "alpha          1.2312      0.039     31.667      0.000         1.155     1.307\n",
        "==============================================================================\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "x1 is a dichtomous measure for female name of first author, so there's no statsitically significant penalty associated with having a female name, although we are missing a lot of relevant control variables."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "year_2009 = []\n",
      "for article in articles[1:]:\n",
      "    if article[2] == '2009':\n",
      "        year_2009.append(1)\n",
      "    else:\n",
      "        year_2009.append(0)\n",
      "\n",
      "Counter(year_2009)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "Counter({0: 1362, 1: 1245})"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = zip(constant, female, year_2009)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = NegativeBinomial(cites, X)\n",
      "results = model.fit()\n",
      "print(results.summary())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Optimization terminated successfully.\n",
        "         Current function value: 2.883764\n",
        "         Iterations: 10\n",
        "         Function evaluations: 11\n",
        "         Gradient evaluations: 11\n",
        "                     NegativeBinomial Regression Results                      \n",
        "==============================================================================\n",
        "Dep. Variable:                      y   No. Observations:                 2607\n",
        "Model:               NegativeBinomial   Df Residuals:                     2604\n",
        "Method:                           MLE   Df Model:                            2\n",
        "Date:                Wed, 29 Oct 2014   Pseudo R-squ.:                0.004375\n",
        "Time:                        20:28:38   Log-Likelihood:                -7518.0\n",
        "converged:                       True   LL-Null:                       -7551.0\n",
        "                                        LLR p-value:                 4.503e-15\n",
        "==============================================================================\n",
        "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "const          1.6102      0.036     44.198      0.000         1.539     1.682\n",
        "x1             0.0690      0.047      1.453      0.146        -0.024     0.162\n",
        "x2             0.3684      0.046      8.056      0.000         0.279     0.458\n",
        "alpha          1.1967      0.038     31.408      0.000         1.122     1.271\n",
        "==============================================================================\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "x2 is being published in 2009 (as opposed to 2010) and is positively associated with cite count. This make sense, since older articles have more opportunites to be cited. This is also a basic check on whether the model is making any sense."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.decomposition import NMF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = TfidfVectorizer(max_df=0.7, \n",
      "                             min_df=5,\n",
      "                             stop_words='english')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf = vectorizer.fit_transform([article[4] for article in articles[1:]])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nmf = NMF(n_components=25, random_state=1).fit(tfidf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_names = vectorizer.get_feature_names()\n",
      "\n",
      "for topic_idx, topic in enumerate(nmf.components_):\n",
      "    print(\"Topic #%d:\" % topic_idx)\n",
      "    print(\" \".join([feature_names[i]\n",
      "                    for i in topic.argsort()[:-10 - 1:-1]]))\n",
      "    print ''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Topic #0:\n",
        "women gender men gendered employment female male author feminist roles\n",
        "\n",
        "Topic #1:\n",
        "movement movements organizations environmental protest social collective mobilization activists organizational\n",
        "\n",
        "Topic #2:\n",
        "religious religion religiosity attendance church beliefs affiliation christian catholic belief\n",
        "\n",
        "Topic #3:\n",
        "immigrants immigrant born immigration native foreign generation country assimilation mexican\n",
        "\n",
        "Topic #4:\n",
        "black white blacks segregation gap hispanic race whites racial class\n",
        "\n",
        "Topic #5:\n",
        "racial ethnic race whites groups minority americans multiracial african segregation\n",
        "\n",
        "Topic #6:\n",
        "students school college schools high academic achievement student math year\n",
        "\n",
        "Topic #7:\n",
        "children parents child mothers fathers families parent father parental parenting\n",
        "\n",
        "Topic #8:\n",
        "migration rural migrants urban household migrant community areas climate effect\n",
        "\n",
        "Topic #9:\n",
        "health mental physical status disparities adulthood related study symptoms poor\n",
        "\n",
        "Topic #10:\n",
        "family work families conflict parental research life decade structure review\n",
        "\n",
        "Topic #11:\n",
        "marital marriage cohabitation divorce couples married quality marriages cohabiting wives\n",
        "\n",
        "Topic #12:\n",
        "state political policy states world rights countries global economic national\n",
        "\n",
        "Topic #13:\n",
        "educational education attainment inequality countries socioeconomic homogamy college occupational higher\n",
        "\n",
        "Topic #14:\n",
        "welfare poverty housing state households income risk receipt generosity poor\n",
        "\n",
        "Topic #15:\n",
        "labor market workers employment work job earnings wage jobs economic\n",
        "\n",
        "Topic #16:\n",
        "neighborhood neighborhoods violence crime residents residential violent urban disadvantage community\n",
        "\n",
        "Topic #17:\n",
        "capital social cultural status human support resources theory ties refugees\n",
        "\n",
        "Topic #18:\n",
        "sexual sex young sexuality behavior men male behaviors gay gender\n",
        "\n",
        "Topic #19:\n",
        "music work identity self culture cultural article ethnographic interviews practices\n",
        "\n",
        "Topic #20:\n",
        "mortality age birth weight population risk life fertility childhood death\n",
        "\n",
        "Topic #21:\n",
        "model models data method effects level variables using results methods\n",
        "\n",
        "Topic #22:\n",
        "sociology sociological learning teaching research students theory social imagination classroom\n",
        "\n",
        "Topic #23:\n",
        "network networks social ties structure centrality actors bridging exchange homophily\n",
        "\n",
        "Topic #24:\n",
        "care child medical patients patient policy clinical practice services physicians\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topic_predictions = nmf.transform(tfidf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_X = []\n",
      "\n",
      "for row,topics in enumerate(topic_predictions):\n",
      "    x =  list(topic_predictions[row]) + list(X[row])  \n",
      "    new_X.append(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = NegativeBinomial(cites, new_X)\n",
      "results = model.fit(maxiter=2000)\n",
      "print(results.summary())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Optimization terminated successfully.\n",
        "         Current function value: 2.816534\n",
        "         Iterations: 91\n",
        "         Function evaluations: 92\n",
        "         Gradient evaluations: 92\n",
        "                     NegativeBinomial Regression Results                      \n",
        "==============================================================================\n",
        "Dep. Variable:                      y   No. Observations:                 2607\n",
        "Model:               NegativeBinomial   Df Residuals:                     2579\n",
        "Method:                           MLE   Df Model:                           27\n",
        "Date:                Wed, 29 Oct 2014   Pseudo R-squ.:                 0.02759\n",
        "Time:                        21:34:56   Log-Likelihood:                -7342.7\n",
        "converged:                       True   LL-Null:                       -7551.0\n",
        "                                        LLR p-value:                 2.053e-71\n",
        "==============================================================================\n",
        "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "x1             5.7536      1.230      4.678      0.000         3.343     8.164\n",
        "x2             2.2490      0.755      2.980      0.003         0.770     3.728\n",
        "x3             1.6323      0.562      2.902      0.004         0.530     2.735\n",
        "x4             1.8449      0.765      2.411      0.016         0.345     3.345\n",
        "x5             3.0179      0.840      3.593      0.000         1.372     4.664\n",
        "x6             3.7654      0.835      4.508      0.000         2.128     5.403\n",
        "x7             2.2040      0.763      2.888      0.004         0.708     3.700\n",
        "x8             4.5779      0.768      5.963      0.000         3.073     6.083\n",
        "x9             2.3902      0.775      3.083      0.002         0.871     3.910\n",
        "x10            5.5109      0.669      8.243      0.000         4.200     6.821\n",
        "x11            6.7195      0.829      8.103      0.000         5.094     8.345\n",
        "x12            4.5349      0.782      5.801      0.000         3.003     6.067\n",
        "x13            3.5138      0.954      3.682      0.000         1.644     5.384\n",
        "x14            3.1823      0.947      3.361      0.001         1.327     5.038\n",
        "x15            0.8875      0.793      1.119      0.263        -0.668     2.443\n",
        "x16            2.4172      0.932      2.593      0.010         0.590     4.244\n",
        "x17            4.1209      0.824      4.999      0.000         2.505     5.737\n",
        "x18            4.2946      0.841      5.109      0.000         2.647     5.942\n",
        "x19            4.2710      0.858      4.976      0.000         2.589     5.953\n",
        "x20            4.8492      1.152      4.208      0.000         2.590     7.108\n",
        "x21            3.6182      0.878      4.121      0.000         1.898     5.339\n",
        "x22           10.1148      1.093      9.255      0.000         7.973    12.257\n",
        "x23            4.2901      0.971      4.416      0.000         2.386     6.194\n",
        "x24            7.7171      0.784      9.849      0.000         6.181     9.253\n",
        "x25            1.3440      0.918      1.465      0.143        -0.454     3.142\n",
        "const          0.5009      0.096      5.235      0.000         0.313     0.688\n",
        "x26            0.0473      0.047      1.001      0.317        -0.045     0.140\n",
        "x27            0.4107      0.044      9.434      0.000         0.325     0.496\n",
        "alpha          1.0248      0.034     30.114      0.000         0.958     1.091\n",
        "=============================================================================="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pwd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 97,
       "text": [
        "u'/Users/nealcaren/Dropbox/quant-text-fall-2014'"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
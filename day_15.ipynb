{
 "metadata": {
  "name": "",
  "signature": "sha256:eeca18cebf289ba3b04cae68ec9a7dadf7cb62659ffa526573cc5eb169e4e234"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "\n",
      "import requests\n",
      "\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import metrics\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = 'https://raw.githubusercontent.com/nealcaren/quant-text-fall-2014/master/emails.json'\n",
      "emails = requests.get(url).json()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "years = []\n",
      "texts = []\n",
      "senders = []\n",
      "\n",
      "for email in emails:\n",
      "    text = email['copy']\n",
      "    year = int(email['date'].split()[2])\n",
      "    sender = email['sender'].split('@')[-1].split('>')[0].replace('email.','')\n",
      "    if sender == 'barackobama.com':\n",
      "        years.append(year)\n",
      "        texts.append(text)\n",
      "        senders.append(sender)\n",
      "Counter(years)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 132,
       "text": [
        "Counter({2012: 381, 2013: 195, 2014: 145})"
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = TfidfVectorizer(stop_words='english',\n",
      "                             min_df        = .1 ,\n",
      "                             max_df        = .8 ,\n",
      "                             ngram_range   = (1, 2) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer.fit(texts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 134,
       "text": [
        "TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=0.8, max_features=None, min_df=0.1,\n",
        "        ngram_range=(1, 2), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
        "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
        "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
        "        vocabulary=None)"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = vectorizer.transform(texts).toarray()\n",
      "y = years"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = RandomForestClassifier(n_estimators = 5, \n",
      "                             min_samples_leaf = 2)\n",
      "\n",
      "clf.fit(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 136,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=2,\n",
        "            min_samples_split=2, n_estimators=5, n_jobs=1, oob_score=False,\n",
        "            random_state=None, verbose=0)"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metrics.confusion_matrix(y, clf.predict(X))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 137,
       "text": [
        "array([[381,   0,   0],\n",
        "       [  6, 183,   6],\n",
        "       [  1,  11, 133]])"
       ]
      }
     ],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print metrics.classification_report(y, clf.predict(X) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "       2012       0.98      1.00      0.99       381\n",
        "       2013       0.94      0.94      0.94       195\n",
        "       2014       0.96      0.92      0.94       145\n",
        "\n",
        "avg / total       0.97      0.97      0.97       721\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "importances = clf.feature_importances_\n",
      "\n",
      "indices = np.argsort(importances)[::-1]\n",
      "vocab = vectorizer.get_feature_names()\n",
      "\n",
      "# Print the feature ranking\n",
      "print(\"Feature ranking:\")\n",
      "\n",
      "for f in range(10):\n",
      "    word = vocab[indices[f]]\n",
      "    print(\"%d. feature %d - %s - (%f)\" % (f + 1, indices[f],  word, importances[indices[f]]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Feature ranking:\n",
        "1. feature 26 - action contributions - (0.132260)\n",
        "2. feature 245 - paid organizing - (0.118821)\n",
        "3. feature 289 - rganizing action - (0.115105)\n",
        "4. feature 354 - way stay - (0.114960)\n",
        "5. feature 351 - washington - (0.108946)\n",
        "6. feature 241 - organizing action - (0.056687)\n",
        "7. feature 152 - gifts organizing - (0.026860)\n",
        "8. feature 69 - chicago - (0.024183)\n",
        "9. feature 173 - il - (0.014772)\n",
        "10. feature 215 - millions - (0.012605)\n"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline = Pipeline(\n",
      "                    [('clf', RandomForestClassifier()) ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "parameters = {\n",
      "              'clf__max_depth': [3, 5], # maximum depth of the tree\n",
      "              'clf__n_estimators' : [10,20,50],  # number of features to consider when looking for the best split:\n",
      "              'clf__min_samples_leaf' : [ 5, 10] ,  # The minimum number of samples in newly created leaves\n",
      "              'clf__min_samples_split' : [10,20],   # The minimum number of samples required to split an internal node.\n",
      "              }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, cv=10, scoring='f1')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid_search.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 155,
       "text": [
        "GridSearchCV(cv=10,\n",
        "       estimator=Pipeline(steps=[('clf', RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0))]),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=-1,\n",
        "       param_grid={'clf__min_samples_split': [10, 20], 'clf__max_depth': [3, 5], 'clf__min_samples_leaf': [5, 10], 'clf__n_estimators': [10, 20, 50]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring='f1',\n",
        "       verbose=0)"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid_search.grid_scores_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 156,
       "text": [
        "[mean: 0.83823, std: 0.05515, params: {'clf__max_depth': 3, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 10, 'clf__n_estimators': 10},\n",
        " mean: 0.85559, std: 0.09088, params: {'clf__max_depth': 3, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 10, 'clf__n_estimators': 20},\n",
        " mean: 0.86148, std: 0.08351, params: {'clf__max_depth': 3, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 10, 'clf__n_estimators': 50},\n",
        " mean: 0.81156, std: 0.09087, params: {'clf__max_depth': 3, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 20, 'clf__n_estimators': 10},\n",
        " mean: 0.85750, std: 0.04794, params: {'clf__max_depth': 3, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 20, 'clf__n_estimators': 20},\n",
        " mean: 0.85366, std: 0.05721, params: {'clf__max_depth': 3, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 20, 'clf__n_estimators': 50},\n",
        " mean: 0.84265, std: 0.07324, params: {'clf__max_depth': 3, 'clf__min_samples_leaf': 10, 'clf__min_samples_split': 10, 'clf__n_estimators': 10},\n",
        " mean: 0.85135, std: 0.08346, params: {'clf__max_depth': 3, 'clf__min_samples_leaf': 10, 'clf__min_samples_split': 10, 'clf__n_estimators': 20},\n",
        " mean: 0.85248, std: 0.07410, params: {'clf__max_depth': 3, 'clf__min_samples_leaf': 10, 'clf__min_samples_split': 10, 'clf__n_estimators': 50},\n",
        " mean: 0.83492, std: 0.09085, params: {'clf__max_depth': 3, 'clf__min_samples_leaf': 10, 'clf__min_samples_split': 20, 'clf__n_estimators': 10},\n",
        " mean: 0.86334, std: 0.03032, params: {'clf__max_depth': 3, 'clf__min_samples_leaf': 10, 'clf__min_samples_split': 20, 'clf__n_estimators': 20},\n",
        " mean: 0.84884, std: 0.07449, params: {'clf__max_depth': 3, 'clf__min_samples_leaf': 10, 'clf__min_samples_split': 20, 'clf__n_estimators': 50},\n",
        " mean: 0.88610, std: 0.05489, params: {'clf__max_depth': 5, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 10, 'clf__n_estimators': 10},\n",
        " mean: 0.88790, std: 0.04910, params: {'clf__max_depth': 5, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 10, 'clf__n_estimators': 20},\n",
        " mean: 0.88253, std: 0.05169, params: {'clf__max_depth': 5, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 10, 'clf__n_estimators': 50},\n",
        " mean: 0.88761, std: 0.04504, params: {'clf__max_depth': 5, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 20, 'clf__n_estimators': 10},\n",
        " mean: 0.88587, std: 0.04483, params: {'clf__max_depth': 5, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 20, 'clf__n_estimators': 20},\n",
        " mean: 0.89109, std: 0.04492, params: {'clf__max_depth': 5, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 20, 'clf__n_estimators': 50},\n",
        " mean: 0.89549, std: 0.05736, params: {'clf__max_depth': 5, 'clf__min_samples_leaf': 10, 'clf__min_samples_split': 10, 'clf__n_estimators': 10},\n",
        " mean: 0.88220, std: 0.05056, params: {'clf__max_depth': 5, 'clf__min_samples_leaf': 10, 'clf__min_samples_split': 10, 'clf__n_estimators': 20},\n",
        " mean: 0.90222, std: 0.03508, params: {'clf__max_depth': 5, 'clf__min_samples_leaf': 10, 'clf__min_samples_split': 10, 'clf__n_estimators': 50},\n",
        " mean: 0.86920, std: 0.07228, params: {'clf__max_depth': 5, 'clf__min_samples_leaf': 10, 'clf__min_samples_split': 20, 'clf__n_estimators': 10},\n",
        " mean: 0.88735, std: 0.04602, params: {'clf__max_depth': 5, 'clf__min_samples_leaf': 10, 'clf__min_samples_split': 20, 'clf__n_estimators': 20},\n",
        " mean: 0.88509, std: 0.07972, params: {'clf__max_depth': 5, 'clf__min_samples_leaf': 10, 'clf__min_samples_split': 20, 'clf__n_estimators': 50}]"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid_search.best_params_\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 157,
       "text": [
        "{'clf__max_depth': 5,\n",
        " 'clf__min_samples_leaf': 10,\n",
        " 'clf__min_samples_split': 10,\n",
        " 'clf__n_estimators': 50}"
       ]
      }
     ],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction import text\n",
      "\n",
      "stop_words = text.ENGLISH_STOP_WORDS.union(['victoria','bassetti','gmail','unsubscribe','email','430','south',\n",
      "                                            'capital','street', 'authorized','candidate',])\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=stop_words,\n",
      "                             min_df        = .1 ,\n",
      "                             max_df        = .8 ,\n",
      "                             ngram_range   = (1, 2) )\n",
      "\n",
      "X = vectorizer.fit_transform(texts).toarray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = RandomForestClassifier(n_estimators = 10, \n",
      "                             min_samples_leaf = 5,\n",
      "                             max_depth = 5)\n",
      "\n",
      "clf.fit(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 159,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=5, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=5,\n",
        "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0)"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "importances = clf.feature_importances_\n",
      "\n",
      "indices = np.argsort(importances)[::-1]\n",
      "vocab = vectorizer.get_feature_names()\n",
      "\n",
      "# Print the feature ranking\n",
      "print(\"Feature ranking:\")\n",
      "\n",
      "for f in range(10):\n",
      "    word = vocab[indices[f]]\n",
      "    print(\"%d. feature %d - %s - (%f)\" % (f + 1, indices[f],  word, importances[indices[f]]))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Feature ranking:\n",
        "1. feature 286 - rganizing - (0.139732)\n",
        "2. feature 24 - action - (0.080315)\n",
        "3. feature 239 - organizing action - (0.069893)\n",
        "4. feature 238 - organizing - (0.068710)\n",
        "5. feature 88 - contact supporters - (0.067684)\n",
        "6. feature 18 - 66732 - (0.057198)\n",
        "7. feature 348 - washington - (0.056143)\n",
        "8. feature 349 - washington 20035 - (0.056023)\n",
        "9. feature 86 - contact - (0.039244)\n",
        "10. feature 269 - questions - (0.034861)\n"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 148
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}